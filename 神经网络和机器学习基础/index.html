<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>神经网络和机器学习基础 | Welcome To Oa</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/donate.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">神经网络和机器学习基础</h1><a id="logo" href="/.">Welcome To Oa</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/guestbook/"><i class="fa fa-comments"> Guestbook</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">神经网络和机器学习基础</h1><div class="post-meta">May 20, 2018<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">1.</span> <span class="toc-text">神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.1.</span> <span class="toc-text">感知机</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.2.</span> <span class="toc-text">神经网络结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.</span> <span class="toc-text">具体拟合过程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.1.</span> <span class="toc-text">梯度下降（使用mini-batch）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.2.</span> <span class="toc-text">梯度计算（后向传播算法）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#undefined"><span class="toc-number">1.3.3.</span> <span class="toc-text">梯度计算时出现的问题与解决</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">2.</span> <span class="toc-text">机器学习基础</span></a></li></ol></div></div><div class="post-content"><p>紧接着上一篇的<a href="https://jarvis-k.github.io/DL%E5%88%9D%E7%BA%A7%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80/" target="_blank" rel="noopener">DL初级数学基础</a>，这里大致讲一下神经网络和机器学习基础，具体如果以后有时间，应该会参照机器学习（周志华）或者模式识别来分开写。</p>
<h1>神经网络</h1>
<p>说是神经网络，但其实和生物学的神经网络差异还是很大的，这里先介绍下神经网络的最基础结构，也是和生物神经网络比较像的一部分，感知机。</p>
<h2>感知机</h2>
<p>感知机是一个二分类模型，他的结构如下</p>
<p><img src="/神经网络和机器学习基础/1.png" alt="感知机"></p>
<p>就是简单的对所有输入点做一个仿射变换再做一个非线性变换（即激活函数），这个模型就很简单，激活函数有很多种，这里简单列举几个</p>
<ol>
<li>$tanh(x)=(e^x-e^{-x})/(e^x+e^(-x))$</li>
<li>$sigmoid(x)=1/(1+e^{-x})$</li>
<li>$ReLu(x)=max(0,x)$ 之后还会再提到这个函数</li>
</ol>
<p>图像这里就不贴出来了，但是感知机有个问题，就是他只能处理线性可分的数据，而对非线性的，就只能摊手了，所以应用场景就很狭窄。</p>
<h2>神经网络结构</h2>
<p>直接看图好吧</p>
<p><img src="/神经网络和机器学习基础/2.png" alt="神经网络"></p>
<p>这里我们可以看到和感知机还是怪像的，只是比感知机多了个隐藏层，输出层的节点数量增多了。我们上面说感知机是用来处理线性二分类的，而做了这样的改变后，我们基本可以处理任何分类问题（不考虑过拟合的话）。画图/找图+贴图真的是很麻烦的事情，就简单写下重要的概念什么的好了。</p>
<ol>
<li>如果将隐藏层输出值作为z轴，可以看出经过激活函数的非线性变换，将会使不同的数据分布在不同的高度，使其可能转换成线性可分。</li>
<li>如果有足够数量的隐藏层节点，我们可以拟合任意数据(直观理解上我们可以认为对应着无限个线段拼接可形成任意形状)</li>
<li>正因为第二点，所以过拟合是神经网络最大的问题</li>
</ol>
<h2>具体拟合过程</h2>
<h3>梯度下降（使用mini-batch）</h3>
<p>好像上一篇文章有跳过了凸优化部分，那么这里也就大概说下吧（坑留着后面再填）。一般因为Hessain矩阵是很难算的（耗时），所以很多时候我们都是使用的一阶梯度的优化方法，从数据使用上考虑，分为3种：</p>
<ol>
<li>全量数据（full-batch），由于数据量通常很大，每迭代一次就要使用所有数据，很显然是不可行的。</li>
<li>随机梯度下降（SGD），每次迭代只取一个数据，效率和逃出极小值上的效果还是可以的，但随着类别的增多，很容易导致最后也无法收敛。</li>
<li>小批量数据（min-batch），每次迭代取一定量的数据，相当于在前两者中取个均衡，既保证了一定的随机性，又可以防止随机性过大导致的无法收敛，但这个每次取的数据量就是个超参了，一般只能靠经验选取了。</li>
</ol>
<h3>梯度计算（后向传播算法）</h3>
<p>使用梯度下降算法的前提是我们能获得不同层的节点之间的梯度，直接看图：</p>
<p><img src="/神经网络和机器学习基础/3.png" alt=""></p>
<p>很容易理解，从输出节点逐层向输入节点求导，而由于传播时可直接使用前一层求出的导与本层的导数做乘积得到结果，从而避免了重复计算，这就是后向传播算法了。</p>
<h3>梯度计算时出现的问题与解决</h3>
<ol>
<li>梯度消失，由于如果在某一层梯度很小很小（如0.000001）的话，那么在它的传播路径上的梯度都会很小，导致学习效率很低，因此我们一般使用ReLU（梯度为1）或者其他的可以避免梯度衰减的激活函数</li>
<li>梯度爆炸，与第一条相反，如果某一层梯度很大很大（110000）的话，那么传播路径上的梯度都会很大，可能导致震荡或者不收敛，因此我们可以使用K梯度裁剪（如（60，80）则转换成（$60/\sqrt{60^2+80^2}*K,80/\sqrt{60^2+80^2}*K$））的方法，来避免梯度爆炸.</li>
<li>验证梯度的正确性，我们使用数值计算梯度（取一个很小的$\epsilon$,使用定义计算梯度），与解析解做比较，误差范围内接收。</li>
</ol>
<h1>机器学习基础</h1>
<p>这里也只做简单记录几句好了。</p>
<ol>
<li>欠拟合和过拟合</li>
<li>使用验证集避免过拟合</li>
<li>规范化，L1获得稀疏解，L2获得权重二范数较低解</li>
<li>集成学习，综合多个模型结果</li>
<li>随机失活（Dropout），降低特征间关联，增强泛化能力</li>
</ol>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://jarvis.world/神经网络和机器学习基础/" data-id="cjrk6unvq0019nvihjg3x77xa" class="article-share-link">Share</a><div class="tags"><a href="/tags/ML/">ML</a><a href="/tags/DM/">DM</a></div><div class="post-nav"><a href="/mongodb-import-complex-txt/" class="pre">mongodb import complex txt</a><a href="/使用迅雷下载百度云中的文件/" class="next">使用迅雷下载百度云中的文件</a></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  id: '神经网络和机器学习基础',
  owner: 'Jarvis-K',
  repo: 'Jarvis-K.github.io',
  oauth: {
    client_id: 'f5c6bbd5b2ae20c2f136',
    client_secret: 'fed7dc675f5293f90d56d4055654fb89db9003a8',
  },
})
gitment.render('container')</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://jarvis.world"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/Math/" style="font-size: 15px;">Math</a> <a href="/tags/ml-algo/" style="font-size: 15px;">ml-algo</a> <a href="/tags/installation/" style="font-size: 15px;">installation</a> <a href="/tags/Util/" style="font-size: 15px;">Util</a> <a href="/tags/rl-papers/" style="font-size: 15px;">rl-papers</a> <a href="/tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="/tags/util/" style="font-size: 15px;">util</a> <a href="/tags/DL/" style="font-size: 15px;">DL</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/gluon/" style="font-size: 15px;">gluon</a> <a href="/tags/pyqt/" style="font-size: 15px;">pyqt</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/数值计算与优化/" style="font-size: 15px;">数值计算与优化</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a> <a href="/tags/DM/" style="font-size: 15px;">DM</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/EM-Algorithm/">EM Algorithm</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Mean-Field-Multi-Agent-Reinforcement-Learning/">Summary: Mean Field Multi-Agent Reinforcement Learning. ICML(2018)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-ACCNet-Actor-Coordinator-Critic-Net-for-“Learning-to-Communicate”-with-Deep-Multi-agent-Reinforcement-Learning/">Summary: ACCNet: Actor-Coordinator-Critic Net for “Learning-to-Communicate” with Deep Multi-agent Reinforcement Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Emergence-of-Grounded-Compositional-Language-in-Multi-Agent-Populations/">Summary: Emergence of Grounded Compositional Language in Multi-Agent Populations(AAAI 2018)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Learning-Multiagent-Communication-with-Backpropagation/">Summary: Learning Multiagent Communication with Backpropagation(Nips 2016)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Learning-to-Communicate-with-Deep-Multi-Agent-Reinforcement-Learning/">Summary: Learning to Communicate with Deep Multi-Agent Reinforcement Learning(Nips 2016)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-TarMAC-Targeted-Multi-Agent-Communication/">Summary: TarMAC:Targeted Multi-Agent Communication</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Intrinsic-Social-Motivation-Via-Causal-Influence-In-Multi-Agent-RL/">Summary: Intrinsic Social Motivation Via Causal Influence In Multi-Agent RL</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Actor-Attention-Critic-For-Multi-Agent-Reinforcement-Learning/">Summary: Actor-Attention-Critic For Multi-Agent Reinforcement Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Learning-Attentional-Communication-for-Multi-Agent-Cooperation/">Summary: Learning Attentional Communication for Multi-Agent Cooperation</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://cww97.cn/" title="cww" target="_blank">cww</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Welcome To Oa.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>