<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Hypergraph Convolution and Hyper Attention | Welcome To Oa</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="/css/donate.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Hypergraph Convolution and Hyper Attention</h1><a id="logo" href="/.">Welcome To Oa</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/guestbook/"><i class="fa fa-comments"> Guestbook</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Hypergraph Convolution and Hyper Attention</h1><div class="post-meta">Apr 29, 2019<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">Contents</div><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">2.</span> <span class="toc-text">What is Hypergraph</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">3.</span> <span class="toc-text">Hyper Conv</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">4.</span> <span class="toc-text">Hyper Attention</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#undefined"><span class="toc-number">5.</span> <span class="toc-text">More have not been done</span></a></li></ol></div></div><div class="post-content"><h1>Introduction</h1>
<ul>
<li>Author: Oxford</li>
<li>contribution: proposed end to end tranable conv and attention for hypergraph.</li>
<li><a href="https://arxiv.org/abs/1901.08150" target="_blank" rel="noopener">paper</a></li>
</ul>
<h1>What is Hypergraph</h1>
<p>A simple graph's edge connect two vertices, while hypergraph's edge connects more than two vertices.As shown in fig1:
<img src="/Hypergraph-Convolution-and-Hyper-Attention/fig1.png" alt=""></p>
<p>Let $\mathcal { G } = ( V , E )$ be vera hypergraph with $N$ vertices and $M$ hyperedges. Each hyperedge $\epsilon \in E$ is assigned with a positive weight $W _ { \epsilon \epsilon }$, with all the weights stored in a diagonal matrix $\mathbf { W } \in \mathbb { R } ^ { M \times M }$.This</p>
<p>Different from simple graph which has an adjacency matrix, hypergraph use incidence matrix $\mathbf { H } \in \mathbb { R } ^ { N \times M }$ to represent graph's connections. If $v_i$ is connected by $\epsilon$, the $H_{i\epsilon}=1$,otherwise 0.Then the vertex degree is
$$D _ { i i } = \sum _ { \epsilon = 1 } ^ { M } W _ { \epsilon \epsilon } H _ { i \epsilon }$$
and the hyperedge degree is
$$B _ { \epsilon \epsilon } = \sum _ { i = 1 } ^ { N } H _ { i \epsilon }$$
and the vertices' feature is $X$</p>
<h1>Hyper Conv</h1>
<p>Assumtions:</p>
<ol>
<li>more propagaions should be done between those vertices connected by a common hyperedge</li>
<li>the hyperedges with larger weights deserve more confidence in propagations.</li>
</ol>
<p>So one step conv can be:
$$x _ { i } ^ { ( l + 1 ) } = \sigma \left( \sum _ { j = 1 } ^ { N } \sum _ { \epsilon = 1 } ^ { M } H _ { i \epsilon } H _ { j \epsilon } W _ { \epsilon \epsilon } x _ { j } ^ { ( l ) } \mathbf { P } \right)$$</p>
<p>Written in matrix form:
$$\mathbf { X } ^ { ( l + 1 ) } = \sigma \left( \mathbf { H } \mathbf { W } \mathbf { H } ^ { \mathrm { T } } \mathbf { X } ^ { ( l ) } \mathbf { P } \right)$$</p>
<p>However $\mathbf { H } \mathbf { W } \mathbf { H } ^ { \mathrm { T } } $ does not hold a constrainted spectal radius, which means the scale of $X^l$ (here means distribution in my thoughts) will be changed.This will lead to numerical instabilities and increase the risk of exploding/vanishing gradients when stack multi hpyer conv layer together. So the author impose normalization here:
$$\mathbf { X } ^ { ( l + 1 ) } = \sigma \left( \mathbf { D } ^ { - 1 / 2 } \mathbf { H } \mathbf { W } \mathbf { B } ^ { - 1 } \mathbf { H } ^ { \mathrm { T } } \mathbf { D } ^ { - 1 / 2 } \mathbf { X } ^ { ( l ) } \mathbf { P } \right)$$</p>
<h1>Hyper Attention</h1>
<p>The incidence matrix $\mathbf{H}$ can be thought some kind of Attention matrix, but it was not learnable and trainable after defined before.</p>
<p>So here the author proposed Hyper Attention.However  hypergraph attention is only feasible when the vertex set and the hyperedge set are from (or can be projected to) the same homogeneous domain, since only in this case, the similarities between vertices and hyperedges are directly comparable.Then the author choose a simple way: each vertex collects its K-nearest neighbors to form a hyper-edge.Then the attention score can be:
$$H _ { i j } = \frac { \exp \left( \sigma \left( \operatorname { sim } \left( x _ { i } \mathbf { P } , x _ { j } \mathbf { P } \right) \right) \right) } { \sum _ { k \in \mathcal { N } _ { i } } \exp \left( \sigma \left( \operatorname { sim } \left( x _ { i } \mathbf { P } , x _ { k } \mathbf { P } \right) \right) \right) }$$
and \sin ( \cdot ) is a similarity function that computes the pairwise similarities between two verticies.</p>
<h1>More have not been done</h1>
<ol>
<li>Hyper Attention on heterogeneous domain.</li>
<li>Why not treat the hyperedge as fully connected subgraph? better or worse than GCN+Polling or HGN?</li>
</ol>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="https://jarvis.world/Hypergraph-Convolution-and-Hyper-Attention/" data-id="cjv2m69a100081xihhfmc0s4q" class="article-share-link">Share</a><div class="tags"><a href="/tags/gnn-papers/">gnn-papers</a></div><div class="post-nav"><a href="/EM-Algorithm/" class="next">EM Algorithm</a></div><div id="container"></div><link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css"><script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script><script>var gitment = new Gitment({
  id: 'Hypergraph Convolution and Hyper Attention',
  owner: 'Jarvis-K',
  repo: 'Jarvis-K.github.io',
  oauth: {
    client_id: 'f5c6bbd5b2ae20c2f136',
    client_secret: 'fed7dc675f5293f90d56d4055654fb89db9003a8',
  },
})
gitment.render('container')</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://jarvis.world"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/util/" style="font-size: 15px;">util</a> <a href="/tags/Math/" style="font-size: 15px;">Math</a> <a href="/tags/ml-algo/" style="font-size: 15px;">ml-algo</a> <a href="/tags/gnn-papers/" style="font-size: 15px;">gnn-papers</a> <a href="/tags/installation/" style="font-size: 15px;">installation</a> <a href="/tags/Util/" style="font-size: 15px;">Util</a> <a href="/tags/rl-papers/" style="font-size: 15px;">rl-papers</a> <a href="/tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="/tags/DL/" style="font-size: 15px;">DL</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/gluon/" style="font-size: 15px;">gluon</a> <a href="/tags/pyqt/" style="font-size: 15px;">pyqt</a> <a href="/tags/cv/" style="font-size: 15px;">cv</a> <a href="/tags/数值计算与优化/" style="font-size: 15px;">数值计算与优化</a> <a href="/tags/ML/" style="font-size: 15px;">ML</a> <a href="/tags/DM/" style="font-size: 15px;">DM</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/Hypergraph-Convolution-and-Hyper-Attention/">Hypergraph Convolution and Hyper Attention</a></li><li class="post-list-item"><a class="post-list-link" href="/EM-Algorithm/">EM Algorithm</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Mean-Field-Multi-Agent-Reinforcement-Learning/">Summary: Mean Field Multi-Agent Reinforcement Learning. ICML(2018)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-ACCNet-Actor-Coordinator-Critic-Net-for-“Learning-to-Communicate”-with-Deep-Multi-agent-Reinforcement-Learning/">Summary: ACCNet: Actor-Coordinator-Critic Net for “Learning-to-Communicate” with Deep Multi-agent Reinforcement Learning</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Emergence-of-Grounded-Compositional-Language-in-Multi-Agent-Populations/">Summary: Emergence of Grounded Compositional Language in Multi-Agent Populations(AAAI 2018)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Learning-Multiagent-Communication-with-Backpropagation/">Summary: Learning Multiagent Communication with Backpropagation(Nips 2016)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Learning-to-Communicate-with-Deep-Multi-Agent-Reinforcement-Learning/">Summary: Learning to Communicate with Deep Multi-Agent Reinforcement Learning(Nips 2016)</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-TarMAC-Targeted-Multi-Agent-Communication/">Summary: TarMAC:Targeted Multi-Agent Communication</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Intrinsic-Social-Motivation-Via-Causal-Influence-In-Multi-Agent-RL/">Summary: Intrinsic Social Motivation Via Causal Influence In Multi-Agent RL</a></li><li class="post-list-item"><a class="post-list-link" href="/Summary-Actor-Attention-Critic-For-Multi-Agent-Reinforcement-Learning/">Summary: Actor-Attention-Critic For Multi-Agent Reinforcement Learning</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="https://cww97.cn/" title="cww" target="_blank">cww</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">Welcome To Oa.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>